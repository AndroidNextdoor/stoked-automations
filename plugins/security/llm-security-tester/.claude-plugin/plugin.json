{
  "name": "llm-security-tester",
  "version": "2025.0.0",
  "description": "LLM security testing for prompt injection, jailbreaking, data poisoning, and AI model vulnerabilities - comprehensive OWASP LLM Top 10 testing",
  "category": "security",
  "keywords": [
    "llm-security",
    "prompt-injection",
    "jailbreaking",
    "ai-security",
    "data-poisoning",
    "model-inversion",
    "owasp-llm",
    "ml-security",
    "chatbot-security",
    "rag-security"
  ],
  "author": {
    "name": "Andrew Nixdorf",
    "email": "[email protected]"
  },
  "repository": "https://github.com/AndroidNextdoor/stoked-automations",
  "license": "MIT"
}
